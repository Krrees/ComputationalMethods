{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we have a list of tokens, represented as strings.\n",
      "\n",
      "We can combine them, split them, interleave them.\n",
      "\n",
      "But these aren't just strings -- they are words. And an abstract word can show up in many guises, varying by:  \n",
      "    - capitalization\n",
      "    - inflection: tense, number, gender, morphological case ...\n",
      "\n",
      "It'd be nice to normalize these. We normalized capitalization (case) already, but we could do the same by these other things. How?  \n",
      "\n",
      "1. figure out what part of speech something is\n",
      "2. use that to determine what its morphemes are\n",
      "3. remove them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "text = \"She listened to me and my brother\"\n",
      "\n",
      "verbs = [\"listen\"]\n",
      "nouns = [\"brother\"]\n",
      "pronouns = [\"she\", \"me\"]\n",
      "possPronouns = [\"my\", \"your\"]\n",
      "\n",
      "def tokenizeText(txt):\n",
      "    \"\"\"splits a punctuation-less sentence into lowercased tokens\"\"\"\n",
      "    tokens = text.split(\" \") #separate on spaces\n",
      "    tokensOut = []           # what we will return\n",
      "    # now loop through tokens, lower each token and add that to tokensOut\n",
      "    for token in tokens:\n",
      "        tmod = token.lower()\n",
      "        tokensOut.append(tmod)\n",
      "    \n",
      "    return tokensOut\n",
      "\n",
      "\n",
      "tokens = tokenizeText(text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['she', 'listened', 'to', 'me', 'and', 'my', 'brother']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"She listened to me and my brother\"\n",
      "\n",
      "verbs = [\"listen\"]\n",
      "nouns = [\"brother\"]\n",
      "pronouns = [\"she\", \"me\", \"i\"]\n",
      "possPronouns = [\"my\", \"your\"]\n",
      "\n",
      "def normalizeV(v):\n",
      "    \"\"\"removes tense from regular verbs\"\"\"\n",
      "    # get rid of ed, ing, and s at the end of verbs\n",
      "    if v[-2:] == \"ed\":\n",
      "        return v[:-2]\n",
      "    elif v[:-3] == \"ing\":\n",
      "        return v[:-3]\n",
      "    elif v[-1] == \"s\":\n",
      "        return v[:-1]\n",
      "    # remember the elsewhere case: in general return the v\n",
      "    # (if we returned NOTHING, we'd lose the verb)\n",
      "    else:\n",
      "        return v\n",
      "\n",
      "def normalizeN(n):\n",
      "    \"\"\"removes plural from regular nouns\"\"\"\n",
      "    # strip off plural\n",
      "    if n[-1] == \"s\":\n",
      "        return n[:-1]\n",
      "    else:\n",
      "        return n\n",
      "\n",
      "def normalizePoss(possPro):\n",
      "    #change my to i and your to you\n",
      "    if possPro == \"my\":\n",
      "        return \"i\"    #remember we are lower casing here\n",
      "    elif possPro == \"your\":\n",
      "        return \"you\"\n",
      "    else:\n",
      "        return possPro\n",
      "        \n",
      "    \n",
      "def tokenizeText(txt):\n",
      "    \"\"\"splits a punctuation-less sentence into lowercased tokens\"\"\"\n",
      "    tokens = text.split(\" \") #separate on spaces\n",
      "    tokensOut = []           # what we will return\n",
      "    # now loop through tokens, lower each token and add that to tokensOut\n",
      "        tmod = token.lower()\n",
      "        # this part checks if something is in a class and then runs the \n",
      "        # appropriate morphological normalizer\n",
      "        if tmod in verbs:\n",
      "            tmod = normalizeV(tmod)\n",
      "        elif tmod in nouns:\n",
      "            tmod = normalizeN(tmod)\n",
      "        elif tmod in possPronouns:\n",
      "            tmod = normalizePoss(tmod)\n",
      "        tokensOut.append(tmod)\n",
      "    \n",
      "    return tokensOut\n",
      "\n",
      "\n",
      "tokens = tokenizeText(text)\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['she', 'listened', 'to', 'me', 'and', 'i', 'brother']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But this doesn't seem to handle what we want. We sort of want to have the actual form being used AND the underlying representation. This just backs off to the base.\n",
      "\n",
      "Our problem is that strings are a poor substitute for a real word, which has: \n",
      "\n",
      "- a root\n",
      "- some inflection\n",
      "- a part of speech\n",
      "- other stuff\n",
      "\n",
      "We need a new type: **WORD**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "New types in Python are called **classes**. Like all types in Python, classes are objects, bundles of properties and methods that operate on those properties.\n",
      "\n",
      "We might want a word class that has:\n",
      "\n",
      "* properties\n",
      "    * literal form\n",
      "    * root\n",
      "    * inflection\n",
      "    * part of speech\n",
      "* methods\n",
      "    * change inflection (tense, plurality)\n",
      "    * change part of speech (nominalize, verbalize, etc.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see classes in action by trying something we haven't seen before. Let's look at the [`datetime`](http://docs.python.org/2/library/datetime.html) module, which handles dates and times.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "\n",
      "yesterday = datetime.date(2013, 10,1)    #initialize a new date object with some data\n",
      "\n",
      "tomorrow = datetime.date(2013, 10, 3)    #initialize a new date object with some data\n",
      "\n",
      "print tomorrow-yesterday #gives the difference in a timedelta\n",
      "print type(tomorrow-yesterday)\n",
      "\n",
      "difference = datetime.timedelta(10)  #10 day difference\n",
      "print tomorrow+difference\n",
      "print tomorrow-difference\n",
      "\n",
      "print (tomorrow-difference).day\n",
      "print (tomorrow).weekday()\n",
      "print (tomorrow-difference).strftime(\"%A %b %d, %Y\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 days, 0:00:00\n",
        "<type 'datetime.timedelta'>\n",
        "2013-10-13\n",
        "2013-09-23\n",
        "23\n",
        "3\n",
        "Monday Sep 23, 2013\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# making a new class\n",
      "class Word(object):\n",
      "    # this is the initializing function of the object\n",
      "    # it's run whenever we make a new object\n",
      "    \n",
      "    # self: a representation of the object inside the object\n",
      "    def __init__(self, word, pos):\n",
      "        self.word = word  #assign the objects internal properties accordingly\n",
      "        # note that word and self.word are different, because they are in \n",
      "        # different namespaces\n",
      "        self.pos = pos\n",
      "        self.lowered = word.lower()\n",
      "        \n",
      "        #very weird...call methods are part of self\n",
      "        self.normalize()\n",
      "        \n",
      "    def normalize(self):\n",
      "        \"\"\"adds a root property to the object\"\"\"\n",
      "\n",
      "        # putting a function in the scope of another; perfectly fine.\n",
      "        def normalizeV(v):\n",
      "            \"\"\"removes tense from regular verbs\"\"\"\n",
      "            # get rid of ed, ing, and s at the end of verbs\n",
      "            if v[-2:] == \"ed\":\n",
      "                return v[:-2]\n",
      "            elif v[:-3] == \"ing\":\n",
      "                return v[:-3]\n",
      "            elif v[-1] == \"s\":\n",
      "                return v[:-1]\n",
      "        # remember the elsewhere case: in general return the v\n",
      "        # (if we returned NOTHING, we'd lose the verb)\n",
      "            else:\n",
      "                return v\n",
      "\n",
      "        # normalize only verbs because that is what we have\n",
      "        if self.pos == \"V\":\n",
      "            self.root = normalizeV(self.word)\n",
      "        else:\n",
      "            self.root = word\n",
      "            \n",
      "    def inflect(self, tense):\n",
      "        \"\"\"add tense inflection for a verb; takes present, past, future for tense\"\"\"\n",
      "    \n",
      "        # add the regular endings\n",
      "        if self.pos == \"V\":\n",
      "            if tense == \"present\":\n",
      "                return self.word #not worrying about 3rd sg\n",
      "            if tense == \"past\":\n",
      "                return self.word + \"ed\"\n",
      "            if tense == \"future\":\n",
      "                return \"will \" + self.word\n",
      "        else:\n",
      "            return self.word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listen = Word()  #missing the word and pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "__init__() takes exactly 3 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-51-fc904def6636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlisten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#missing the word and pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 3 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listen = Word(\"listen\", \"V\")\n",
      "print listen.pos\n",
      "print listen.inflect(\"past\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "V\n",
        "listened\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}